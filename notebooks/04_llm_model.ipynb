{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c57ee79-6ba0-4c3b-a53f-29118314689d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/baran/.conda/envs/stackoverflow/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda115.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/baran/.conda/envs/stackoverflow/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 115\n",
      "CUDA SETUP: Loading binary /home/baran/.conda/envs/stackoverflow/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda115.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baran/.conda/envs/stackoverflow/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/baran/.conda/envs/stackoverflow/lib/libcudart.so.11.0'), PosixPath('/home/baran/.conda/envs/stackoverflow/lib/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss, jaccard_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline, TrainingArguments, Trainer, AutoModelForSequenceClassification, DataCollatorWithPadding, EvalPrediction\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950c4e89-c857-4fca-bf9c-c83e9563ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config variables and constants\n",
    "dataset_path = Path(\"../datasets\")\n",
    "dataset_path.mkdir(exist_ok=True)\n",
    "\n",
    "model_name = \"facebook/opt-6.7b\"\n",
    "\n",
    "MAX_LEN = 2048\n",
    "train_batch_size = 8\n",
    "eval_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "learning_rate = 2e-4\n",
    "epoch = 1\n",
    "metric_name = \"f1\"\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "free_in_GB = int(torch.cuda.mem_get_info()[0] / 1024**3)\n",
    "max_memory = f\"{free_in_GB-2}GB\"\n",
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "max_memory = {i: max_memory for i in range(n_gpus)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bde4070-7801-4db8-9cba-20e5f3b5a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b706cb-342c-4b0e-b91a-882d497a4a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80096f240af42e9a03bd7c066c2076f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbebde2ea06e47bda4e0ac132a383df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257fef914edb40a69846f805d3e86e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f1af258a8e4e0aaecfc1e2591315a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbc60f2bc084a97b11b557af7039be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, problem_type=\"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a04342-56c1-40f1-9997-240cc59465f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_parquet(dataset_path/\"cleaned_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "969327ee-f8fb-4cac-a1a4-f28049b036c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>BodyCleaned</th>\n",
       "      <th>TitleCleaned</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sql,asp.net</td>\n",
       "      <td>Has anyone got experience creating SQL-based A...</td>\n",
       "      <td>ASP.NET Site Maps</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c#,.net</td>\n",
       "      <td>I have a little game written in C#. It uses a ...</td>\n",
       "      <td>Adding scripting functionality to .NET applica...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c++</td>\n",
       "      <td>I am working on a collection of classes used f...</td>\n",
       "      <td>Should I use nested classes in this case?</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.net</td>\n",
       "      <td>I've been writing a few web services for a .ne...</td>\n",
       "      <td>Homegrown consumption of web services</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sql-server</td>\n",
       "      <td>I wonder how you guys manage deployment of a d...</td>\n",
       "      <td>Deploying SQL Server Databases from Test to Live</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830491</th>\n",
       "      <td>javascript</td>\n",
       "      <td>I'm trying to detect the \"flash out of date\" e...</td>\n",
       "      <td>YouTube iFrame API: no ready call, no error call</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830492</th>\n",
       "      <td>python</td>\n",
       "      <td>I need to extend a shell script (bash). As I a...</td>\n",
       "      <td>How to execute multiline python code from a ba...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830493</th>\n",
       "      <td>php</td>\n",
       "      <td>I am building a custom MVC project and I have ...</td>\n",
       "      <td>URL routing in PHP (MVC)</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830494</th>\n",
       "      <td>android</td>\n",
       "      <td>Under minifyEnabled I changed from false to tr...</td>\n",
       "      <td>Obfuscating code in android studio</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830495</th>\n",
       "      <td>javascript</td>\n",
       "      <td>I have input which I use to filter my array of...</td>\n",
       "      <td>How to fire function after v-model change?</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830496 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tag                                        BodyCleaned  \\\n",
       "0       sql,asp.net  Has anyone got experience creating SQL-based A...   \n",
       "1           c#,.net  I have a little game written in C#. It uses a ...   \n",
       "2               c++  I am working on a collection of classes used f...   \n",
       "3              .net  I've been writing a few web services for a .ne...   \n",
       "4        sql-server  I wonder how you guys manage deployment of a d...   \n",
       "...             ...                                                ...   \n",
       "830491   javascript  I'm trying to detect the \"flash out of date\" e...   \n",
       "830492       python  I need to extend a shell script (bash). As I a...   \n",
       "830493          php  I am building a custom MVC project and I have ...   \n",
       "830494      android  Under minifyEnabled I changed from false to tr...   \n",
       "830495   javascript  I have input which I use to filter my array of...   \n",
       "\n",
       "                                             TitleCleaned  \\\n",
       "0                                       ASP.NET Site Maps   \n",
       "1       Adding scripting functionality to .NET applica...   \n",
       "2               Should I use nested classes in this case?   \n",
       "3                   Homegrown consumption of web services   \n",
       "4        Deploying SQL Server Databases from Test to Live   \n",
       "...                                                   ...   \n",
       "830491   YouTube iFrame API: no ready call, no error call   \n",
       "830492  How to execute multiline python code from a ba...   \n",
       "830493                           URL routing in PHP (MVC)   \n",
       "830494                 Obfuscating code in android studio   \n",
       "830495         How to fire function after v-model change?   \n",
       "\n",
       "                                                   labels  \n",
       "0       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "3       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "830491  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "830492  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "830493  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "830494  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "830495  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "\n",
       "[830496 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = df_full[\"Tag\"].apply(lambda x: (x.split(',')))\n",
    "binarizer =  MultiLabelBinarizer()\n",
    "labels = binarizer.fit_transform(tags)\n",
    "df_full[\"labels\"] = list(labels)\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87433021-3815-4549-9cb6-34d195cb37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_title, x_test_title, y_train, y_test = train_test_split(df_full[\"TitleCleaned\"], df_full[\"labels\"], test_size=0.1, random_state = 0)\n",
    "x_train_body, x_test_body, y_train, y_test = train_test_split(df_full[\"BodyCleaned\"], df_full[\"labels\"], test_size=0.1, random_state = 0)\n",
    "samples = x_test_body.sample(1000)\n",
    "samples_y = y_test[samples.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec49a59c-d6e5-4f37-8d70-8c3e0036fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = utils.StackOverflowDS(x_train_body.reset_index(drop=True), y_train.reset_index(drop=True), tokenizer, MAX_LEN)\n",
    "dataset_test = utils.StackOverflowDS(x_test_body.reset_index(drop=True), y_test.reset_index(drop=True), tokenizer, MAX_LEN)\n",
    "dataset_sample = utils.StackOverflowDS(samples.reset_index(drop=True), samples_y.reset_index(drop=True), tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2374222-9701-4162-a008-aa0ff3e706a9",
   "metadata": {},
   "source": [
    "The model we are trying to use is really big and will not fit my GPU memory thats why we will use 8 bit quantization and LORA to make it smaller and faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39b90e6-51f2-4de1-b899-9bff1bf58d2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mbinarizer\u001b[49m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m      2\u001b[0m id2label \u001b[38;5;241m=\u001b[39m {idx:label \u001b[38;5;28;01mfor\u001b[39;00m idx, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(binarizer\u001b[38;5;241m.\u001b[39mclasses_)}\n\u001b[1;32m      3\u001b[0m label2id \u001b[38;5;241m=\u001b[39m {label:idx \u001b[38;5;28;01mfor\u001b[39;00m idx, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(binarizer\u001b[38;5;241m.\u001b[39mclasses_)}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'binarizer' is not defined"
     ]
    }
   ],
   "source": [
    "num_labels = len(binarizer.classes_)\n",
    "id2label = {idx:label for idx, label in enumerate(binarizer.classes_)}\n",
    "label2id = {label:idx for idx, label in enumerate(binarizer.classes_)}\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, mlm=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, \n",
    "                                                           num_labels=num_labels, \n",
    "                                                           problem_type=\"multi_label_classification\",\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id,\n",
    "                                                           load_in_8bit=True, \n",
    "                                                           device_map='auto',\n",
    "                                                           max_memory=max_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4be810-03bb-4e57-affe-69d4e5dde895",
   "metadata": {},
   "outputs": [],
   "source": [
    "### there is a post processing needed for the peft library\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # freeze the model - train adapters later\n",
    "    if param.ndim == 1:\n",
    "        # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "        param.data = param.data.to(torch.float32)\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "    def forward(self, x):\n",
    "        return super().forward(x).to(torch.float32)\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb6319-3663-4c3b-9c9d-fc5f6d2c1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081b964-ad7a-4924-8519-f6042d546445",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(f\"{model_name}\", \n",
    "                         evaluation_strategy = \"epoch\",\n",
    "                         save_strategy = \"epoch\",\n",
    "                         learning_rate=learning_rate,\n",
    "                         per_device_train_batch_size=train_batch_size,\n",
    "                         per_device_eval_batch_size=eval_batch_size,\n",
    "                         gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                         num_train_epochs=epoch,\n",
    "                         weight_decay=0.01,\n",
    "                         warmup_steps=100, \n",
    "                         max_steps=200, \n",
    "                         load_best_model_at_end=True,\n",
    "                         metric_for_best_model=metric_name,\n",
    "                         fp16=True,\n",
    "                         logging_steps=1, \n",
    "                         output_dir=model_path\n",
    "                        )\n",
    "\n",
    "trainer = Trainer(model=model, args=args, train_dataset=dataset_train, \n",
    "                  #eval_dataset=dataset_sample,\n",
    "                  eval_dataset=dataset_test, \n",
    "                  tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackoverflow",
   "language": "python",
   "name": "stackoverflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
