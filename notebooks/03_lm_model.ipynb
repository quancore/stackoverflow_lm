{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b84d3e-5e9b-4330-8320-3cfc36eaac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss, jaccard_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline, TrainingArguments, Trainer, AutoModelForSequenceClassification, DataCollatorWithPadding, EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d47d34-c65a-4773-a88e-9d858d4ee90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config variables and constants\n",
    "dataset_path = Path(\"../datasets\")\n",
    "dataset_path.mkdir(exist_ok=True)\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "MAX_LEN = 512\n",
    "train_batch_size = 8\n",
    "eval_batch_size = 4\n",
    "learning_rate = 1e-05\n",
    "epoch = 1\n",
    "metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524439ed-0d60-4484-91cf-6964bfaa8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackOverflowDS(Dataset):\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        cleaned_text = str(self.text[index])\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            cleaned_text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            #padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True      \n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[index], dtype=torch.float)            \n",
    "        }\n",
    "\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    # return as dictionary\n",
    "    metrics = {'F1': f1_score(y_true, y_pred, average=\"weighted\"),\n",
    "               'ROC_AUC': roc_auc_score(y_true, y_pred, average = 'weighted'),\n",
    "               'Hamming': hamming_loss(y_true, y_pred)*100,\n",
    "               'Jaccard': jaccard_score(y_true, y_pred, average=\"weighted\"),\n",
    "               'Accuracy': accuracy_score(y_true, y_pred)}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5e942b-94c9-4f44-91aa-1b4b0f7a5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_parquet(dataset_path/\"cleaned_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877cc621-147f-40a8-b6c8-6e9c2867926a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>BodyCleaned</th>\n",
       "      <th>TitleCleaned</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sql,asp.net</td>\n",
       "      <td>Has anyone got experience creating SQL-based A...</td>\n",
       "      <td>ASP.NET Site Maps</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c#,.net</td>\n",
       "      <td>I have a little game written in C#. It uses a ...</td>\n",
       "      <td>Adding scripting functionality to .NET applica...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c++</td>\n",
       "      <td>I am working on a collection of classes used f...</td>\n",
       "      <td>Should I use nested classes in this case?</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.net</td>\n",
       "      <td>I've been writing a few web services for a .ne...</td>\n",
       "      <td>Homegrown consumption of web services</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sql-server</td>\n",
       "      <td>I wonder how you guys manage deployment of a d...</td>\n",
       "      <td>Deploying SQL Server Databases from Test to Live</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830491</th>\n",
       "      <td>javascript</td>\n",
       "      <td>I'm trying to detect the \"flash out of date\" e...</td>\n",
       "      <td>YouTube iFrame API: no ready call, no error call</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830492</th>\n",
       "      <td>python</td>\n",
       "      <td>I need to extend a shell script (bash). As I a...</td>\n",
       "      <td>How to execute multiline python code from a ba...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830493</th>\n",
       "      <td>php</td>\n",
       "      <td>I am building a custom MVC project and I have ...</td>\n",
       "      <td>URL routing in PHP (MVC)</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830494</th>\n",
       "      <td>android</td>\n",
       "      <td>Under minifyEnabled I changed from false to tr...</td>\n",
       "      <td>Obfuscating code in android studio</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830495</th>\n",
       "      <td>javascript</td>\n",
       "      <td>I have input which I use to filter my array of...</td>\n",
       "      <td>How to fire function after v-model change?</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830496 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tag                                        BodyCleaned  \\\n",
       "0       sql,asp.net  Has anyone got experience creating SQL-based A...   \n",
       "1           c#,.net  I have a little game written in C#. It uses a ...   \n",
       "2               c++  I am working on a collection of classes used f...   \n",
       "3              .net  I've been writing a few web services for a .ne...   \n",
       "4        sql-server  I wonder how you guys manage deployment of a d...   \n",
       "...             ...                                                ...   \n",
       "830491   javascript  I'm trying to detect the \"flash out of date\" e...   \n",
       "830492       python  I need to extend a shell script (bash). As I a...   \n",
       "830493          php  I am building a custom MVC project and I have ...   \n",
       "830494      android  Under minifyEnabled I changed from false to tr...   \n",
       "830495   javascript  I have input which I use to filter my array of...   \n",
       "\n",
       "                                             TitleCleaned  \\\n",
       "0                                       ASP.NET Site Maps   \n",
       "1       Adding scripting functionality to .NET applica...   \n",
       "2               Should I use nested classes in this case?   \n",
       "3                   Homegrown consumption of web services   \n",
       "4        Deploying SQL Server Databases from Test to Live   \n",
       "...                                                   ...   \n",
       "830491   YouTube iFrame API: no ready call, no error call   \n",
       "830492  How to execute multiline python code from a ba...   \n",
       "830493                           URL routing in PHP (MVC)   \n",
       "830494                 Obfuscating code in android studio   \n",
       "830495         How to fire function after v-model change?   \n",
       "\n",
       "                                                   labels  \n",
       "0       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "3       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "830491  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "830492  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "830493  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "830494  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "830495  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "\n",
       "[830496 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = df_full[\"Tag\"].apply(lambda x: (x.split(',')))\n",
    "binarizer =  MultiLabelBinarizer()\n",
    "labels = binarizer.fit_transform(tags)\n",
    "df_full[\"labels\"] = list(labels)\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ca9f92-0e9b-4db6-89e7-d6585e7f05a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_title, x_test_title, y_train, y_test = train_test_split(df_full[\"TitleCleaned\"], df_full[\"labels\"], test_size=0.1, random_state = 0)\n",
    "x_train_body, x_test_body, y_train, y_test = train_test_split(df_full[\"BodyCleaned\"], df_full[\"labels\"], test_size=0.1, random_state = 0)\n",
    "samples = x_test_body.sample(1000)\n",
    "samples_y = y_test[samples.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d7d4db-5f4d-45d4-8e75-1d394f9e8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, problem_type=\"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45f26d-9d0f-40dd-9205-8f169039360e",
   "metadata": {},
   "source": [
    "## Using zero shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a766926b-0b8e-438f-845f-8f9aac28e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "# classifier = pipeline(model=model_name_small, task=\"zero-shot-classification\", device=0)\n",
    "# predictions = classifier(samples.to_list(), binarizer.classes_, multi_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69906361-8a8b-4461-8d80-bd8755233e0c",
   "metadata": {},
   "source": [
    "## Finetune a LM for downstream task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1144846-83fb-4564-a3e9-685efe1434aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(binarizer.classes_)\n",
    "id2label = {idx:label for idx, label in enumerate(binarizer.classes_)}\n",
    "label2id = {label:idx for idx, label in enumerate(binarizer.classes_)}\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, \n",
    "                                                           problem_type=\"multi_label_classification\",\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7424cc9-4059-4454-8ac1-cf03174f4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = StackOverflowDS(x_train_body.reset_index(drop=True), y_train.reset_index(drop=True), tokenizer, MAX_LEN)\n",
    "dataset_test = StackOverflowDS(x_test_body.reset_index(drop=True), y_test.reset_index(drop=True), tokenizer, MAX_LEN)\n",
    "dataset_sample = StackOverflowDS(samples.reset_index(drop=True), samples_y.reset_index(drop=True), tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3916cd9b-e9a6-459c-8ecb-d87eb207550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(f\"{model_name}\", \n",
    "                         evaluation_strategy = \"epoch\",\n",
    "                         save_strategy = \"epoch\",\n",
    "                         learning_rate=learning_rate,\n",
    "                         per_device_train_batch_size=train_batch_size,\n",
    "                         per_device_eval_batch_size=eval_batch_size,\n",
    "                         num_train_epochs=epoch,\n",
    "                         weight_decay=0.01,\n",
    "                         load_best_model_at_end=True,\n",
    "                         metric_for_best_model=metric_name,\n",
    "                         output_dir=model_path\n",
    "                        )\n",
    "trainer = Trainer(model=model, args=args, train_dataset=dataset_train, \n",
    "                  #eval_dataset=dataset_sample,\n",
    "                  eval_dataset=dataset_test, \n",
    "                  tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e5d6b-6950-4b77-8edd-5b20684beee6",
   "metadata": {},
   "source": [
    "Get zero shot evaluation on our sample of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82343e5e-09aa-491f-9b55-7ba03b2d8ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7095041871070862,\n",
       " 'eval_F1': 0.11609777163263978,\n",
       " 'eval_ROC_AUC': 0.49808693274758437,\n",
       " 'eval_Hamming': 60.211111111111116,\n",
       " 'eval_Jaccard': 0.06330936731748303,\n",
       " 'eval_Accuracy': 0.0,\n",
       " 'eval_runtime': 7.9594,\n",
       " 'eval_samples_per_second': 125.637,\n",
       " 'eval_steps_per_second': 31.409}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80f257-4aa3-4084-ad42-9749cdfc80af",
   "metadata": {},
   "source": [
    "zero shot performance is really bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a47d17-e74e-46ad-9281-9a110bf02f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baran/.conda/envs/stackoverflow/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='79147' max='93431' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [79147/93431 4:28:17 < 48:25, 4.92 it/s, Epoch 0.85/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4aa63b-0d5b-4ce4-a8d5-134084d2ea3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackoverflow",
   "language": "python",
   "name": "stackoverflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
